{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xin Chen's implementation of the MBE-NN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author: Xin Chen\n",
    "* Email: Bismarrck@me.com\n",
    "\n",
    "This jupyter notebook is used to repeat the work of http://doi.org/10.1021/acs.jctc.6b00994. \n",
    "\n",
    "The test cluster is $B_{20}$. The reference energies are calculated with CP2K-2.4 at tne PBE level using DZVP basis and GTH potentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the deep convolutional neural network for the $Pt_{13}$ cluster is as follows:\n",
    "\n",
    "<img src=\"./convnet.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "The input features are transformed interatomic distances. The output node represents the estimated DFT energies.\n",
    "The detailed explanantion of this convolutionary neural network will be given in the following section **Inference**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we shall import python modules and declare global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The patch size is always 1x1\n",
    "PATCH_SIZE = 1\n",
    "\n",
    "# The HDF5 database file.\n",
    "HDF5_DATABASE_FILE = \"c9h7n.hdf5\"\n",
    "\n",
    "# The dimension of the cluster.\n",
    "NUM_SITES = 20\n",
    "\n",
    "# The total number of structures in the XYZ file should be 209660.\n",
    "XYZ_FILE = \"c9h7n.xyz\"\n",
    "TOTAL_SIZE = 100\n",
    "\n",
    "# Setup the dataset partitions.\n",
    "TEST_SIZE = 10\n",
    "VALID_SIZE = 10\n",
    "TRAIN_SIZE = 60\n",
    "LOAD_SIZE = TEST_SIZE + VALID_SIZE + TRAIN_SIZE\n",
    "\n",
    "# Setup the random seed.\n",
    "SEED = 235\n",
    "\n",
    "# Setup the precision of floats. \n",
    "tf_type = tf.float32\n",
    "np_type = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This convnet is a slightly different from normal convolutionary neural networks. Suppose N is the batch size:\n",
    "\n",
    "* The shape of the input tensor is: $[N, 1, C_{N}^{k}, C_{k}^{2}]$\n",
    "* The **k** defines the many-body expansion. In this paper, k is selected to be 4.\n",
    "* The patch (kernel) is always 1x1.\n",
    "* The padding scheme is 'SAME' and the strides are 1 in both directions.\n",
    "* A shape transpose action should be taken between layer 4 and 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good habit to setup the scope name for every tensor. So we define a helper function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(tensor):\n",
    "  \"\"\"\n",
    "  Attach a lot of summaries to a Tensor (for TensorBoard visualization).\n",
    "\n",
    "  Args:\n",
    "    tensor: a Tensor.\n",
    "\n",
    "  \"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(tensor)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tensor, mean))))\n",
    "      tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(tensor))\n",
    "    tf.summary.scalar('min', tf.reduce_min(tensor))\n",
    "    tf.summary.histogram('histogram', tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
